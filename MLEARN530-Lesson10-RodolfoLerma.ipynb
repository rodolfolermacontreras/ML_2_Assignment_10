{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLFLOW - Deploying Machine Learning in Production (Assignment 10)\n",
    "\n",
    "## Student: Rodolfo Lerma\n",
    "\n",
    "In this assignment you will be writing a script that train models and use `mlflow` to submit runs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./new_data.json\n",
    "{\"age\": {\"0\": 40, \"1\": 47},\n",
    " \"balance\": {\"0\": 580, \"1\": 3644},\n",
    " \"campaign\": {\"0\": 1, \"1\": 2},\n",
    " \"contact\": {\"0\": \"unknown\", \"1\": \"unknown\"},\n",
    " \"day\": {\"0\": 16, \"1\": 9},\n",
    " \"default\": {\"0\": \"no\", \"1\": \"no\"},\n",
    " \"duration\": {\"0\": 192, \"1\": 83},\n",
    " \"education\": {\"0\": \"secondary\", \"1\": \"secondary\"},\n",
    " \"housing\": {\"0\": \"yes\", \"1\": \"no\"},\n",
    " \"job\": {\"0\": \"blue-collar\", \"1\": \"services\"},\n",
    " \"loan\": {\"0\": \"no\", \"1\": \"no\"},\n",
    " \"marital\": {\"0\": \"married\", \"1\": \"single\"},\n",
    " \"month\": {\"0\": \"may\", \"1\": \"jun\"},\n",
    " \"pdays\": {\"0\": -1, \"1\": -1},\n",
    " \"poutcome\": {\"0\": \"unknown\", \"1\": \"unknown\"},\n",
    " \"previous\": {\"0\": 0, \"1\": 0}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load all necessary libraries\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import joblib\n",
    "import json\n",
    "\n",
    "# Load Dataset\n",
    "bank = pd.read_csv('bank-full.csv', delimiter = ';')\n",
    "\n",
    "# Split data between train and validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(bank.drop(columns = \"y\"), bank[\"y\"], \n",
    "                                                    test_size = 0.10, random_state = 42)\n",
    "\n",
    "X_train = X_train.reset_index(drop = True)\n",
    "X_test = X_test.reset_index(drop = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1: Create pre-processing function to be later used as part of the pipeline (custom transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformations(df):\n",
    "    onehoter = #To Do\n",
    "    cat_cols = X_train.select_dtypes(['object']).columns\n",
    "    onehoter.fit(X_train[cat_cols])\n",
    "    onehot_cols = #to Do Get Feature Names\n",
    "    df_onehot = #To Do\n",
    "   \n",
    "    num_cols = X_train.select_dtypes(['integer', 'float']).columns\n",
    "    znormalizer = StandardScaler()\n",
    "    znormalizer.fit(X_train[num_cols])\n",
    "    df_norm = #To Do\n",
    "\n",
    "    df_featurized = df_onehot \n",
    "    df_featurized[num_cols] = df_norm \n",
    "\n",
    "    del df_onehot, df_norm\n",
    "    return df_featurized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2: Creating a custom transformer from the previously defined function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processing = #To Do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 3: Creating the pipeline and defining each of two steps: (i) pre-processing, and; (ii) model (Logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    (#To Do)\n",
    "], verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 4: Call `fit` and `predict` on the pipeline to make sure that it all works. Remember to pass them the **un-processed** (original) data, since the data processing should be built into the pipeline now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set parameters for Logistic Regression estimator ('model') inside the pipeline\n",
    "pipeline.set_params(model__C=#To Do,                 # C: default=1.0\n",
    "                    model__solver=#To Do',   # solver: {‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’}, default=’lbfgs’\n",
    "                    model__max_iter=#To Do,         # max_iter: default=100\n",
    "                    model__fit_intercept=True,   # fit_intercept:{True, False}, default=True\n",
    "                    model__penalty='l2')         # penalty: {‘l1’, ‘l2’, ‘elasticnet’, ‘none’}, default=’l2’ \n",
    "                                                 # Warning: The choice of the algorithm depends on the penalty chosen. \n",
    "                                                 #          Not all algorithms support every type of penalty \n",
    "\n",
    "#Fit Training Data to Model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "#Prediction on Training and Test Data\n",
    "y_train_pred = #To Do\n",
    "y_test_pred = #To Do\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 5: Evaluate your model by calculating the precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a function to evaluate the model performance using precision and recall\n",
    "def eval_metrics(actual, pred):\n",
    "    precision = #To Do\n",
    "    recall = #To Do\n",
    "    \n",
    "    return precision, recall\n",
    "\n",
    "#Calculation of evaluation metrics - Precision and Recall for training and validation data\n",
    "(precision_train, recall_train) = #To Do\n",
    "(precision_test, recall_test) = #To Do\n",
    "\n",
    "# Print Model (Logistic Regression) parameters\n",
    "print()\n",
    "print('Main Parameters used in logistic regression are: C={}, solver={}, max_iter={}, fit_intercept={} and penalty={}'.format(pipeline['model'].get_params()['C'],\n",
    "                                                                                                                             pipeline['model'].get_params()['solver'],\n",
    "                                                                                                                             pipeline['model'].get_params()['max_iter'],\n",
    "                                                                                                                             pipeline['model'].get_params()['fit_intercept'],\n",
    "                                                                                                                             pipeline['model'].get_params()['penalty']))\n",
    "# Print Evaluation Metrics for the Model (Logistic Regression)\n",
    "print()\n",
    "print('Precision = {:.2f}% and recall = {:.2f}% on the training data.'.format(precision_train, recall_train))\n",
    "print('Precision = {:.2f}% and recall = {:.2f}% on the validation data.'.format(precision_test, recall_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 6: Save your pipeline object using `joblib` as shown [here](https://sklearn.org/modules/model_persistence.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store 'pipeline' as pickle file using joblib\n",
    "#To Do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 7: Now write a **new script** for scoring: it loads the pipeline you saved in the last step, reads the data `../data/new_data.json` and converts it to a `pandas.DataFrame` object, and obtains predictions on it. The predictions should be stored as a `json` file `../data/new_preds.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call and load stored 'pipeline' \n",
    "pipeline = #To Do\n",
    "\n",
    "#Read json file with new data and write into a pandas dataframe  \n",
    "with open('./new_data.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "new_predictions = pd.DataFrame(data)\n",
    "\n",
    "#Use predict method of pipeline to score (make prediction) on new data \n",
    "new_predictions['prediction'] = #To Do\n",
    "\n",
    "#Write predictions of new data into a json file\n",
    "new_predictions.to_json('./new_preds.json', orient='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read json file containing predictions made for the new data and load them into a dataframe\n",
    "with open('./new_preds.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "new_pred_dataframe= pd.DataFrame(data)\n",
    "\n",
    "#Print predictions for each observation contained in the new_data.json file and the dataframe with the data and prediction\n",
    "print(new_pred_dataframe['prediction'])\n",
    "new_pred_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 8: Create a new text cell in your Notebook: Complete a 50-100 word summary (or short description of your thinking in applying this week's learning to the solution) of your experience in this assignment. Include: What was your incoming experience with this model, if any? what steps you took, what obstacles you encountered. how you link this exercise to real-world, machine learning problem-solving. (What steps were missing? What else do you need to learn?) This summary allows your instructor to know how you are doing and allot points for your effort in thinking and planning, and making connections to real-world work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
